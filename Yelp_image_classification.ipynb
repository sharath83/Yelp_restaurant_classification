{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following program extracts features from images of a restaurant from VGG net pretrained model\n",
    "Paper: Very Deep Convolutional Networks for Large-Scale Image Recognition K. Simonyan, A. Zisserman\n",
    "arXiv:1409.1556\n",
    "\n",
    "#VGG16 model - ILSVRC - 2014 competition\n",
    "#Mean = [103.909, 116.779, 123.68]\n",
    "#BGR format\n",
    "\n",
    "I have tried to extract hidden layer activations from different layers of the network for every image and averaged the mean of all images belong to one restaurant. I have used the averaged activation values as features for restaurants.\n",
    "\n",
    "I have used Theano and Keras for extracting layer level weights and activations for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Yelp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#import h5py\n",
    "#import cv2\n",
    "from scipy.misc import imread, imresize, imshow\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.generic_utils import Progbar\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Sharath/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.11-64/tmpizvobt/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/Sharath/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.11-64/tmpizvobt/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: Tesla K20c (CNMeM is disabled, CuDNN 3007)\n",
      "Using Theano backend.\n",
      "C:\\Users\\Sharath\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "#Deep learning packages\n",
    "import theano\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.activations import relu\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "train_biz = pd.read_csv(\"train_photo_to_biz_ids.csv\")\n",
    "test_biz = pd.read_csv(\"test_photo_to_biz.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the data\n",
    "train.head()\n",
    "train_biz.head()\n",
    "train_biz.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.isnull().values.any()\n",
    "train.isnull().sum() #4 NAs in labels\n",
    "train = train.dropna()\n",
    "#Change the train data type\n",
    "train[\"labels\"]\n",
    "labels = [l.split() for l in train[\"labels\"]]\n",
    "labels = map((lambda x: [int(i) for i in x]), labels)\n",
    "train[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resize, reshape as per input layer of VGG - [None,3,224,224]\n",
    "# As per VGG paper - input is mean subtracted 224X224 RGB image\n",
    "def input_adjust(path):\n",
    "    pic = imread(path) #reads in rgb format\n",
    "    pic = imresize(pic, (224,224,3)) #As required for input layer\n",
    "    pic = pic.astype(np.float32)\n",
    "    \n",
    "    #Convert to BGR format\n",
    "#     pic = pic[:,:,[2,1,0]]\n",
    "#     pic[:,:,0] -= 103.909\n",
    "#     pic[:,:,1] -= 116.779\n",
    "#     pic[:,:,2] -= 123.68\n",
    "    \n",
    "    #read in RGB, keeping the same format\n",
    "    pic[:,:,0] -= 123.68\n",
    "    pic[:,:,1] -= 116.779\n",
    "    pic[:,:,2] -= 103.909\n",
    "    \n",
    "    #reshape to 3X224X224\n",
    "    pic = pic.reshape(3,224,224)\n",
    "    pic = pic.astype(np.float32)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_biz_feature(features):\n",
    "    f = features.mean(axis = 0)\n",
    "    return list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_feature(features):\n",
    "    f = features.max(axis = 0)\n",
    "    return list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "K. Simonyan, A. Zisserman\n",
    "arXiv:1409.1556'''\n",
    "#VGG16 model - ILSVRC - 2014 competition\n",
    "#Mean = [103.909, 116.779, 123.68]\n",
    "#BGR format\n",
    "#\n",
    "\n",
    "def VGG_16(weights_path = None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1), input_shape = (3,224,224)))\n",
    "    model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_network():\n",
    "    model = VGG_16('vgg16_weights.h5')\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "    #Now get the layers of interest from VGG net\n",
    "    #We are interested in using the layers of net before the dense layer\n",
    "    my_out = model.layers[32].get_output(train = False)\n",
    "    input_layer = model.get_input(train = False)\n",
    "\n",
    "    my_net = theano.function([input_layer], my_out)\n",
    "       \n",
    "    return my_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extended_network():\n",
    "    model = VGG_16('vgg16_weights.h5')\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    \n",
    "    #Now get the layers of interest from VGG net\n",
    "    #We are interested in using the layers of net before the dense layer\n",
    "    dense2 = model.layers[34].get_output(train = False)\n",
    "    dense1 = model.layers[33].get_input(train = False)\n",
    "\n",
    "    ext_net = theano.function([dense1], dense2)\n",
    "    return ext_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_net = extended_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First get the network with the layers of interest from VGG net\n",
    "net = get_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get features for train businesses\n",
    "folder = \"F:\\\\sharath\\\\yelpdata\\\\train_photos\"\n",
    "train_data = pd.DataFrame(columns=[\"BusinessId\",\"Target\",\"Features\"])\n",
    "train_features = []\n",
    "status = Progbar(train.shape[0])\n",
    "for idx, row in train.iterrows():\n",
    "    labels = row[\"labels\"]\n",
    "    bid = row[\"business_id\"]\n",
    "\n",
    "    #for a given business ID get the photo IDs\n",
    "    pic_ids = train_biz.loc[(train_biz.business_id == bid),\"photo_id\"]\n",
    "    pic_path = [os.path.join(folder,str(p)+\".jpg\").replace(\"\\\\\",\"/\") for p in pic_ids]\n",
    "    #Get pics in the format required for VGG\n",
    "    pics = [input_adjust(path) for path in pic_path]\n",
    "    pics = np.array(pics)\n",
    "    pics = pics.reshape(len(pics),3,224,224)\n",
    "    pics = pics.astype(np.float32)\n",
    "    print(\"\\n %d pics for business ID %s is ready for net\" %(pics.shape[0], str(bid)))\n",
    "    \n",
    "    #Get 4096 length feature vector for every pic in pics (that belong to a business ID)\n",
    "    #The features are generated from VGG network upto 37th layer (Before the dense layers)\n",
    "    #features = net(pics) #shape should be = len(pic_ids) X 4096\n",
    "    \n",
    "    #Unfortunately, I am getting a memory failure error when my input size is more than 30X3X224X224 in gpu\n",
    "    #It is working fine in cpu because virtual memory feature of cpu. gpu requires contiguous memory allocation,\n",
    "    #which might fail occassionally while working with large arrays\n",
    "    \n",
    "    #A small work around to avoid memory failure in gpu\n",
    "    length = int(pics.shape[0])\n",
    "    features = np.zeros(shape=[length,4096])\n",
    "    for i in range(0,length,30):\n",
    "        start = i\n",
    "        if i+30 <= length:\n",
    "            end = i+30\n",
    "        else:\n",
    "            end = length\n",
    "        features[start:end,:] = net(pics[start:end,:,:,:])\n",
    "        #print(start, end)\n",
    "\n",
    "    #Store the features of each pic\n",
    "    train_features.append([pic_ids, features]) #pics_features[0-1996][0-1]\n",
    "\n",
    "    #Get the mean feature for all the pics that belong to a business\n",
    "    business_feature = get_biz_feature(features)\n",
    "    train_data.loc[idx] = [bid, labels, business_feature]\n",
    "    status.add(1)\n",
    "    \n",
    "#Save pics wise features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_pics.pkl_2\", \"wb\") as f:\n",
    "    pickle.dump(train_features, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "print(\"features for train photos saved to %s\" %(\"F:\\sharath\\yelpdata\\\\train_pics.pkl_2\"))\n",
    "\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_data_2.csv\", \"w\") as f:\n",
    "    train_data.to_csv(f, index = False)\n",
    "f.close()\n",
    "print(\"features for train businesses saved to %s\" %(\"F:\\sharath\\yelpdata\\\\train_data_2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"F:\\sharath\\yelpdata\\\\train_data.csv\", \"w\") as f:\n",
    "    train_data.to_csv(f, index = False)\n",
    "f.close()\n",
    "print(\"features for train businesses saved to %s\" %(\"F:\\sharath\\yelpdata\\\\train_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get features for test businesses\n",
    "folder = \"F:\\\\sharath\\\\yelpdata\\\\test_photos\"\n",
    "#test = pd.read_csv(\"test_photo_to_biz.csv\")\n",
    "test_bids = set(test_biz.business_id.values) #get unique business IDs\n",
    "test_bids = [bid for bid in test_bids] #convert into a pure list\n",
    "test_data = pd.DataFrame(columns=[\"BusinessId\",\"Features\"])\n",
    "test_features = []\n",
    "\n",
    "start = time.time()\n",
    "status = Progbar(len(test_bids))\n",
    "for idx, bid in enumerate(test_bids):\n",
    "    #for a given business ID get the photo IDs\n",
    "    pic_ids = test_biz.loc[(test_biz.business_id == bid),\"photo_id\"]\n",
    "    \n",
    "    #To minimize the time, I will consider max 150 pics per restaurant\n",
    "    if len(pic_ids) > 100:\n",
    "        t = random.sample(range(len(pic_ids)), 100)\n",
    "        pic_ids = pic_ids.iloc[t]\n",
    "    \n",
    "    pic_path = [os.path.join(folder,str(p)+\".jpg\") for p in pic_ids]\n",
    "    \n",
    "    #Get pics in the format required for VGG\n",
    "    pics = [input_adjust(path) for path in pic_path]\n",
    "    pics = np.array(pics)\n",
    "    pics = pics.reshape(len(pics),3,224,224)\n",
    "    print(\"\\n %d pics for business ID %s is ready for net\" %(pics.shape[0], str(bid)))\n",
    "    \n",
    "    #Get 4096 length feature vector for every pic in pics (that belong to a business ID)\n",
    "    #The features are generated from VGG network upto 37th layer (Before the dense layers)\n",
    "    #features = net(pics) #shape should be = len(pic_ids) X 4096\n",
    "    \n",
    "    #Unfortunately, I am getting a memory failure error when my input size is more than 30X3X224X224 in gpu\n",
    "    #It is working fine in cpu because virtual memory feature. gpu requires contiguous memory allocation,\n",
    "    #which might fail occassionally while working with large arrays\n",
    "    \n",
    "    #A small work around to avoid memory failure in gpu\n",
    "    length = int(pics.shape[0])\n",
    "    features = np.zeros(shape=[length,4096])\n",
    "    for i in range(0,length,30):\n",
    "        start = i\n",
    "        if i+30 <= length:\n",
    "            end = i+30\n",
    "        else:\n",
    "            end = length\n",
    "        features[start:end,:] = net(pics[start:end,:,:,:])\n",
    "        #print(start, end)\n",
    "\n",
    "    #Store the features of each pic\n",
    "    test_features.append([pic_ids, features]) #pics_features[0-1996][0-1]\n",
    "\n",
    "    #Get the mean feature for all the pics that belong to a business\n",
    "    business_feature = get_biz_feature(features)\n",
    "    test_data.loc[idx] = [bid, business_feature]\n",
    "    status.add(1)\n",
    "print(\"Time taken for test features %d\" %(time.time()-start))\n",
    "    \n",
    "#Save pics wise features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_pics_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_features, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "print(\"features for test photos saved to %s\" %(\"F:\\sharath\\yelpdata\\\\test_pics_2.pkl\"))\n",
    "    \n",
    "#Save business features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_data_2.csv\", \"w\") as f:\n",
    "    test_data.to_csv(f, index = False)\n",
    "f.close()\n",
    "print(\"features for test businesses saved to %s\" %(\"F:\\sharath\\yelpdata\\\\test_data_2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train data 1996 biz ids\n",
    "#test data 10000 biz ids\n",
    "#feed through layer 33 to 34 (dense1 to dense2)\n",
    "def get_out34(df):\n",
    "\n",
    "    input_train_32 = df.ix[:,\"Features\"]\n",
    "    input_train_32 =  map((lambda x: [float(f) for f in x[1:-1].split(\",\")]), input_train_32)\n",
    "    input_train_32 = np.array(input_train_32, dtype=np.float32)\n",
    "\n",
    "    # get output of 34 layer\n",
    "    out_train_34 = ext_net(input_train_32)\n",
    "    return out_train_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_2 = pd.read_csv(\"F:\\sharath\\yelpdata\\\\train_data_2.csv\")\n",
    "out_train_34=get_out34(train_data_2)\n",
    "#Create a new df\n",
    "t=out_train_34.tolist()\n",
    "train_data_3 = pd.DataFrame(columns=[\"BusinessId\",\"Target\",\"Features\"])\n",
    "for idx, row in train_data_2.iterrows():\n",
    "    train_data_3.loc[idx] = [row[\"BusinessId\"],row[\"Target\"], t[idx]]\n",
    "#Save business features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_data_3.csv\", \"w\") as f:\n",
    "    train_data_3.to_csv(f, index = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test data 10000 biz ids\n",
    "#feed through layer 33 to 34 (dense1 to dense2)\n",
    "test_data_2 = pd.read_csv(\"F:\\sharath\\yelpdata\\\\test_data_2.csv\")\n",
    "out_test_34=get_out34(test_data_2)\n",
    "#Create a new df\n",
    "t=out_test_34.tolist()\n",
    "test_data_3 = pd.DataFrame(columns=[\"BusinessId\",\"Features\"])\n",
    "for idx, row in test_data_2.iterrows():\n",
    "    test_data_3.loc[idx] = [row[\"BusinessId\"], t[idx]]\n",
    "#Save business features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_data_3.csv\", \"w\") as f:\n",
    "    test_data_3.to_csv(f, index = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996/1996 [==============================] - 19s    \n"
     ]
    }
   ],
   "source": [
    "#load 32 layer o/p of each pic and feed fwd to 34th layer\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_pics.pkl\", \"rb\") as f:\n",
    "    train_pics = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "#\n",
    "df = pd.read_csv(\"F:\\sharath\\yelpdata\\\\train_data.csv\")\n",
    "train_data = pd.DataFrame(columns=[\"BusinessId\",\"Target\",\"Features\"])\n",
    "train_features = []\n",
    "status = Progbar(len(train_pics))\n",
    "for idx, pic_data in enumerate(train_pics):\n",
    "    Xin = np.array(pic_data[1], dtype=np.float32)\n",
    "    Xout = ext_net(Xin)\n",
    "     \n",
    "    #Store the features of each pic\n",
    "    train_features.append([pic_data[0], Xout]) #pics_features[0-1996][0-1]\n",
    "\n",
    "    #Get the mean feature for all the pics that belong to a business\n",
    "    business_feature = get_biz_feature(Xout)\n",
    "    train_data.loc[idx] = [df.ix[idx,\"BusinessId\"], df.ix[idx,\"Target\"], business_feature]\n",
    "    status.add(1)\n",
    "\n",
    "#Save business features - RGB - 2nd Dense layer - mean features = 1996X4096 size\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_data_5.csv\", \"w\") as f:\n",
    "    train_data.to_csv(f, index = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#load 32 layer o/p of each pic and get feed fwd to 34th layer\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_pics.pkl\", \"rb\") as f:\n",
    "    test_pics = pickle.load(f)\n",
    "f.close()\n",
    "print len(test_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 238s   \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\sharath\\yelpdata\\\\test_data.csv\")\n",
    "test_data = pd.DataFrame(columns=[\"BusinessId\",\"Features\"])\n",
    "test_features = []\n",
    "status = Progbar(len(test_pics))\n",
    "for idx, pic_data in enumerate(test_pics):\n",
    "    Xin = np.array(pic_data[1], dtype=np.float32)\n",
    "    Xout = ext_net(Xin)\n",
    "     \n",
    "    #Store the features of each pic\n",
    "    test_features.append([pic_data[0], Xout]) #pics_features[0-1996][0-1]\n",
    "\n",
    "    #Get the mean feature for all the pics that belong to a business\n",
    "    business_feature = get_biz_feature(Xout)\n",
    "    test_data.loc[idx] = [df.ix[idx,\"BusinessId\"], business_feature]\n",
    "    status.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save business features for test data - RGB - 2nd Dense layer - mean features = 10000X4096 size\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_data_5.csv\", \"w\") as f:\n",
    "    test_data.to_csv(f, index = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996/1996 [==============================] - 14s    \n"
     ]
    }
   ],
   "source": [
    "#Get max feature from pics feature = biz featute (instead of mean)\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_pics.pkl\", \"rb\") as f:\n",
    "    train_pics = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "#\n",
    "df = pd.read_csv(\"F:\\sharath\\yelpdata\\\\train_data.csv\")\n",
    "train_data = pd.DataFrame(columns=[\"BusinessId\",\"Target\",\"Features\"])\n",
    "train_features = []\n",
    "status = Progbar(len(train_pics))\n",
    "for idx, pic_data in enumerate(train_pics):\n",
    "    Xin = np.array(pic_data[1], dtype=np.float32)\n",
    "    \n",
    "    #Get the mean feature for all the pics that belong to a business\n",
    "    business_feature = get_biz_feature(Xin)\n",
    "    train_data.loc[idx] = [df.ix[idx,\"BusinessId\"], df.ix[idx,\"Target\"], business_feature]\n",
    "    status.add(1)\n",
    "\n",
    "#Save business features - RGB - 2nd Dense layer - mean features = 1996X4096 size\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_data_6.csv\", \"w\") as f:\n",
    "    train_data.to_csv(f, index = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 83s    \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\sharath\\yelpdata\\\\test_data.csv\")\n",
    "test_data = pd.DataFrame(columns=[\"BusinessId\",\"Features\"])\n",
    "test_features = []\n",
    "status = Progbar(len(test_pics))\n",
    "for idx, pic_data in enumerate(test_pics):\n",
    "    Xin = np.array(pic_data[1], dtype=np.float32)\n",
    "\n",
    "    #Get the mean feature for all the pics that belong to a business\n",
    "    business_feature = get_biz_feature(Xin)\n",
    "    test_data.loc[idx] = [df.ix[idx,\"BusinessId\"], business_feature]\n",
    "    status.add(1)\n",
    "#Save business features for test data - RGB - 2nd Dense layer - mean features = 10000X4096 size\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_data_6.csv\", \"w\") as f:\n",
    "    test_data.to_csv(f, index = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features for train photos saved to F:\\sharath\\yelpdata\\train_pics_2.pkl\n",
      "features for test photos saved to F:\\sharath\\yelpdata\\test_pics_2.pkl\n"
     ]
    }
   ],
   "source": [
    "# I will save the pickle files for 34th layer pic wise features\n",
    "#train #Save pics wise features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\train_pics_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_features, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "print(\"features for train photos saved to %s\" %(\"F:\\sharath\\yelpdata\\\\train_pics_2.pkl\"))\n",
    "\n",
    "#test #Save pics wise features\n",
    "with open(\"F:\\sharath\\yelpdata\\\\test_pics_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_features, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "print(\"features for test photos saved to %s\" %(\"F:\\sharath\\yelpdata\\\\test_pics_2.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------- END -----------------------#\n",
    "del test_features, train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_dic = {}\n",
    "n=0\n",
    "for layer in model.layers:\n",
    "    w = layer.get_weights()\n",
    "    weight_dic[n] = w\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(model.layers[33].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG_16('vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "#Now get the layers of interest from VGG net\n",
    "#We are interested in using the layers of net before the dense layer\n",
    "dense2 = model.layers[34].get_output(train = False)\n",
    "dense1 = model.layers[33].get_input(train = False)\n",
    "\n",
    "ext_net = theano.function([dense1], dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"new_weights.hdf5\", \"w\")\n",
    "f.create_dataset(\"dataset_1\", data = new_weights, dtype='float32')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense = model.layers[32].get_output(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = model.get_input(train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_f = theano.function([input_layer], dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im=cv2.imread(\"train_photos/2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = dense_f(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_bool(s):\n",
    "    series = pd.Series([1 if str(i) in str(s).split(\" \") else 0 for i in range(9)])\n",
    "    return series\n",
    "y = train[\"labels\"].apply(to_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.mean()\n",
    "#predict 5,6,8 for all\n",
    "sub[\"labels\"] = \"5 6 8\"\n",
    "sub.to_csv(\"naive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.array(([1,2,3], [2,3,4]), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
