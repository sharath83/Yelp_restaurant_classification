{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t_data => BGR input, 1st dense layer o/p\n",
    "#t_data2 => RGB input, 1st dense layer o/p\n",
    "#t_data3 => RGB i/p, 2nd dense layer o/p but extension on mean image\n",
    "#t_data4 => RGB i/p, 2nd dense layer o/p (extension on total pics) - saved time on test folder by min(pics per biz_id , 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"F:\\sharath\\yelpdata\\\\train_data_4.csv\")\n",
    "test = pd.read_csv(\"F:\\sharath\\yelpdata\\\\test_data_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_test_data(file1, file2):\n",
    "    \n",
    "    path1 = \"F:\\sharath\\yelpdata\\\\\"+file1\n",
    "    path2 = \"F:\\sharath\\yelpdata\\\\\"+file2\n",
    "    train = pd.read_csv(path1)\n",
    "    test = pd.read_csv(path2)\n",
    "\n",
    "    #Create train data for classification\n",
    "    X = train.ix[:,\"Features\"]\n",
    "    X = map((lambda x: [float(f) for f in x[1:-1].split(\",\")]), X)\n",
    "    X = np.array(X)\n",
    "\n",
    "    #binarize the labels for one Vs rest classifier fit\n",
    "    y = train.ix[:,\"Target\"]\n",
    "    y = map((lambda x: [int(i) for i in x[1:-1].split(\",\")]), y)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(y)\n",
    "\n",
    "    #Create test data for prediction\n",
    "    X_test = test.ix[:,\"Features\"]\n",
    "    X_test = map((lambda x: [float(f) for f in x[1:-1].split(\",\")]), X_test)\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    print X.shape, y.shape\n",
    "    print X_test.shape\n",
    "\n",
    "    return X,y,X_test,mlb,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validate(X,y):    \n",
    "    f1_score_svm = []\n",
    "    f1_score_rf = []\n",
    "    kf = KFold(len(X), 3, shuffle=True)\n",
    "    for tr_idx, val_idx in kf:\n",
    "        X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        print X_tr.shape, y_tr.shape\n",
    "        print X_val.shape, y_val.shape\n",
    "\n",
    "        #Fit SVM - OneVsRest\n",
    "        start = time.time()\n",
    "        clf = OneVsRestClassifier(svm.SVC(kernel=\"linear\", probability=True))\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        #print(\"time for fitting svm model %d\" %(time.time()-start))\n",
    "\n",
    "        start = time.time()\n",
    "        pred = clf.predict(X_val)\n",
    "        #print(\"time for prediction %d\" %(time.time()-start))\n",
    "        \n",
    "        #Calculate average f1 score\n",
    "        f1 = round(f1_score(y_val, pred, average=\"micro\"),3)\n",
    "        print(\"f1 score of svm %0.3f\" %(f1))\n",
    "        f1_score_svm.append(f1)\n",
    "\n",
    "        #Fit Random Forest - OneVsRest\n",
    "        start = time.time()\n",
    "        rf = RandomForestClassifier(n_estimators=400, max_depth=150, verbose=0)\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        #print(\"time for fitting rf model %d\" %(time.time()-start))\n",
    "\n",
    "        start = time.time()\n",
    "        pred = rf.predict(X_val)\n",
    "        #print(\"time for prediction %d\" %(time.time()-start))\n",
    "        \n",
    "        #Calculate average f1 score\n",
    "        f1 = round(f1_score(y_val, pred, average=\"micro\"),3)\n",
    "        print (\"f1 score of rf %0.3f\" %(f1))\n",
    "        f1_score_rf.append(f1)\n",
    "\n",
    "    print (\"svm scores:\", f1_score_svm)\n",
    "    print (\"rf scores:\", f1_score_rf)\n",
    "    return f1_score_svm,f1_score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup a cv - data2\n",
    "X,y,X_test2,mlb,test = get_train_test_data(\"train_data_2.csv\", \"test_data_2.csv\")\n",
    "print(\"CV scores on t_data2:\\n\")\n",
    "f1_sv, f1_rf = cross_validate(X,y)\n",
    "\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "    f.write(\"\\nt_data2 results: \\n\")\n",
    "    f.write(\"svm scores: \" + str(f1_sv))\n",
    "    f.write(\"\\nrf scores: \" + str(f1_rf))\n",
    "f.close()\n",
    "\n",
    "# setup a cv - data3\n",
    "X,y,X_test3,mlb,test = get_train_test_data(\"train_data_3.csv\", \"test_data_3.csv\")\n",
    "print(\"CV scores on t_data3:\\n\")\n",
    "f1_sv, f1_rf = cross_validate(X,y)\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "    f.write(\"\\nt_data3 results: \\n\")\n",
    "    f.write(\"svm scores: \" + str(f1_sv))\n",
    "    f.write(\"\\nrf scores: \" + str(f1_rf))\n",
    "f.close()\n",
    "\n",
    "# setup a cv - data4\n",
    "X,y,X_test4,mlb,test = get_train_test_data(\"train_data_4.csv\", \"test_data_4.csv\")\n",
    "print(\"CV scores on t_data4:\\n\")\n",
    "f1_sv, f1_rf = cross_validate(X,y)\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "    f.write(\"\\nt_data4 results: \\n\")\n",
    "    f.write(\"svm scores: \" + str(f1_sv))\n",
    "    f.write(\"\\nrf scores: \" + str(f1_rf))\n",
    "f.close()\n",
    "\n",
    "# setup a cv - data1\n",
    "X,y,X_test,mlb,test = get_train_test_data(\"train_data.csv\", \"test_data.csv\")\n",
    "print(\"CV scores on t_data:\\n\")\n",
    "f1_sv, f1_rf = cross_validate(X,y)\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "    f.write(\"\\nt_data results: \\n\")\n",
    "    f.write(\"svm scores: \" + str(f1_sv))\n",
    "    f.write(\"\\nrf scores: \" + str(f1_rf))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    7.7s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   32.0s\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   48.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996L, 4096L) (1996L, 9L)\n",
      "(10000L, 4096L)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    5.7s finished\n"
     ]
    }
   ],
   "source": [
    "#training on full train data - Random forest\n",
    "X,y,X_test,mlb,test = get_train_test_data(\"train_data_4.csv\", \"test_data_4.csv\")\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel=\"linear\", probability=True))\n",
    "clf.fit(X,y)\n",
    "prob=clf.predict_proba(X_test)\n",
    "#pred=clf.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=500, verbose=1, oob_score=True)\n",
    "rf.fit(X,y)\n",
    "#pred_rf = rf.predict(X_test)\n",
    "prob_rf=rf.predict_proba(X_test)\n",
    "#Calculate average f1 score\n",
    "#f1_score(yts, pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_rf = np.array(prob_rf)\n",
    "prob_rf=prob_rf[:,:,1].T\n",
    "prob_avg = (prob + prob_rf)/2\n",
    "p_rf = prob_avg >0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000L, 9L)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels = mlb.inverse_transform(p_rf)\n",
    "test_labels = [list(label) for label in test_labels]\n",
    "test_labels = map((lambda x: str(x)[1:-1].replace(\",\", \" \")), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare submission file\n",
    "# test = pd.read_csv(\"F:\\sharath\\yelpdata\\\\test_data_4.csv\")\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "sub1 = sub.copy()\n",
    "sub1[[\"business_id\"]] = test[[\"BusinessId\"]]\n",
    "sub1.ix[:,\"labels\"] = test_labels\n",
    "sub1 = pd.merge(sub[[\"business_id\"]], sub1, on = \"business_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003sg</td>\n",
       "      <td>1  2  3  5  6  8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00er5</td>\n",
       "      <td>2  3  5  6  8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00kad</td>\n",
       "      <td>1  2  3  4  5  6  7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00mc6</td>\n",
       "      <td>1  2  3  4  5  6  7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00q7x</td>\n",
       "      <td>1  2  3  5  6  7  8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_id               labels\n",
       "0       003sg     1  2  3  5  6  8\n",
       "1       00er5        2  3  5  6  8\n",
       "2       00kad  1  2  3  4  5  6  7\n",
       "3       00mc6  1  2  3  4  5  6  7\n",
       "4       00q7x  1  2  3  5  6  7  8"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1.to_csv(\"sub_avg_svm_rf_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=1600\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel=\"linear\", probability=True))\n",
    "clf.fit(X[:n,], y[:n,])\n",
    "prob=clf.predict_proba(X[n:n+300,])\n",
    "pred=clf.predict(X[n:n+300,])\n",
    "#f1_score(y[100:200,],prob, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=1600\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=500, verbose=1)\n",
    "rf.fit(X[:n,], y[:n,])\n",
    "prob_rf=rf.predict_proba(X[n:n+300,])\n",
    "pred_rf=rf.predict(X[n:n+300,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print f1_score(y[n:n+300,],pred, average=\"micro\")\n",
    "print f1_score(y[n:n+300,],pred_rf, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_rf = np.array(prob_rf)\n",
    "p_rf=prob_rf[:,:,1]\n",
    "p_rf = p_rf.T\n",
    "p_rf.shape\n",
    "\n",
    "p,p_rf = prob>0.481, p_rf>0.41\n",
    "p=p.astype(np.int)\n",
    "p_rf= p_rf.astype(np.int)\n",
    "print f1_score(y[n:n+300,],p, average=\"micro\")\n",
    "print f1_score(y[n:n+300,],p_rf, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_avg = (prob+prob_rf[:,:,1].T)/2\n",
    "p_avg = prob_avg > 0.42\n",
    "print f1_score(y[n:n+300,],p_avg, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_avg[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
